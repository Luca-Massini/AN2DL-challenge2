{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combined_results.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPV7Gyi0katMzPkx3TMqDTK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAQYRUeguaiM"
      },
      "source": [
        "score = 0.4504 \r\n",
        "\r\n",
        "Here, we combine the results of the networks in order to improve the prediction capability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_PpLe94ubD7"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "cwd = os.getcwd()\r\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB67VDWzptcH",
        "outputId": "f4a6c3aa-db29-4033-9e8f-e94c8a45f089"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXIFzNbaqVWQ"
      },
      "source": [
        "def meanIoU(y_true, y_pred):\r\n",
        "    # get predicted class from softmax\r\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\r\n",
        "\r\n",
        "    per_class_iou = []\r\n",
        "\r\n",
        "    for i in range(1,3): # exclude the background class 0\r\n",
        "      # Get prediction and target related to only a single class (i)\r\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\r\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\r\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\r\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\r\n",
        "    \r\n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\r\n",
        "      per_class_iou.append(iou)\r\n",
        "\r\n",
        "    return tf.reduce_mean(per_class_iou)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxZHqi8LpWJ7"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "model_mais = load_model('/content/drive/MyDrive/second_custom_network_Mais_Dec28_13-20-45.h5',custom_objects={'meanIoU':meanIoU})\r\n",
        "model_haricot = load_model('/content/drive/MyDrive/second_custom_network_Dec28_10-28-05_Haricot.h5',custom_objects={'meanIoU':meanIoU})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXNDsJrCsRDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1fac59-0675-44aa-e7d4-5382b8fa330f"
      },
      "source": [
        "img_h = 384\r\n",
        "img_w = 512\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "class CustomDataSol(tf.keras.utils.Sequence):\r\n",
        "\r\n",
        "  def __init__(self, dataset_dir, img_generator=None,\r\n",
        "               preprocessing_function=None, out_shape=[512, 384],projects=['Weedelec','Pead','Roseau','Bipbip'],plants=['Haricot','Mais']):\r\n",
        "\r\n",
        "    self.subset_filenames = []\r\n",
        "    self.subset_direc = []\r\n",
        "    self.name_project = []\r\n",
        "    self.name_plant = []\r\n",
        "    self.projects = []\r\n",
        "    self.plants = []\r\n",
        "    self.dataset_dir = dataset_dir\r\n",
        "    self.img_generator = img_generator\r\n",
        "    self.preprocessing_function = preprocessing_function\r\n",
        "    self.out_shape = out_shape\r\n",
        "\r\n",
        "    for project in projects :\r\n",
        "      for plant in plants :\r\n",
        "        path=os.path.join(dataset_dir,project,plant)\r\n",
        "        list = os.listdir(os.path.join(path,'Images'))\r\n",
        "        number_files = len(list)\r\n",
        "        for ii in range(0,number_files):\r\n",
        "            self.projects.append(project)\r\n",
        "            self.plants.append(plant)\r\n",
        "            self.subset_filenames.append(os.path.splitext(list[ii])[0])\r\n",
        "            self.subset_direc.append(path)\r\n",
        "            self.name_project.append(project)\r\n",
        "            self.name_plant.append(plant)\r\n",
        "    \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.subset_filenames)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    # Read Image\r\n",
        "    curr_filename = self.subset_filenames[index]\r\n",
        "    curr_dir = self.subset_direc[index]\r\n",
        "    curr_project = self.projects[index]\r\n",
        "    if curr_project == 'Roseau' :\r\n",
        "      img = Image.open(os.path.join(curr_dir, 'Images', curr_filename + '.png'))\r\n",
        "    else :\r\n",
        "      img = Image.open(os.path.join(curr_dir, 'Images', curr_filename + '.jpg'))\r\n",
        "\r\n",
        "    # Resize image \r\n",
        "    img = img.resize(self.out_shape)\r\n",
        "    img_arr = np.array(img)\r\n",
        "    if self.preprocessing_function is not None:\r\n",
        "        img_arr = self.preprocessing_function(img_arr)\r\n",
        "\r\n",
        "    return img_arr\r\n",
        "\r\n",
        "################################################################################\r\n",
        " # Encode array (start kit)\r\n",
        "\r\n",
        "def rle_encode(img):\r\n",
        "    '''\r\n",
        "    img: numpy array, 1 - foreground, 0 - background\r\n",
        "    Returns run length as string formatted\r\n",
        "    '''\r\n",
        "    pixels = img.flatten()\r\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\r\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\r\n",
        "    runs[1::2] -= runs[::2]\r\n",
        "    return ' '.join(str(x) for x in runs)\r\n",
        "\r\n",
        "\r\n",
        "################################################################################\r\n",
        "\r\n",
        "path_test = '/content/drive/My Drive/Development_Dataset/Test_Dev/'\r\n",
        "test_set=CustomDataSol(path_test, \r\n",
        "                        img_generator=None,\r\n",
        "                        projects=['Weedelec','Pead','Roseau','Bipbip'],\r\n",
        "                        plants=['Mais','Haricot'])\r\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test_set,\r\n",
        "                                               output_types= tf.float32,\r\n",
        "                                               output_shapes=[img_h, img_w, 3])\r\n",
        "\r\n",
        "test_dataset = test_dataset.batch(1)\r\n",
        "iterator = iter(test_dataset)\r\n",
        "test_set.__len__()\r\n",
        "    \r\n",
        "submission_dict = {}\r\n",
        "SIZE=[[1536,2048],[2464,3280],[819,1228],[3456,5184]]\r\n",
        "for index in range(0,test_set.__len__()):#\r\n",
        "      image = next(iterator)\r\n",
        "      if test_set.projects[index]=='Bipbip':\r\n",
        "        size_im=SIZE[0]\r\n",
        "      elif test_set.projects[index]=='Pead':\r\n",
        "        size_im=SIZE[1]\r\n",
        "      elif test_set.projects[index]=='Roseau':\r\n",
        "        size_im=SIZE[2]\r\n",
        "      else:\r\n",
        "        size_im=SIZE[3]\r\n",
        "      img_name = os.path.splitext(test_set.subset_filenames[index])[0]\r\n",
        "      submission_dict[img_name] = {}\r\n",
        "      if test_set.plants[index] == 'Mais':\r\n",
        "        model = model_mais\r\n",
        "      else:\r\n",
        "        model = model_haricot\r\n",
        "      mask_arr =  model.predict(image)\r\n",
        "      mask_arr = tf.image.resize(mask_arr, size_im, method='nearest')\r\n",
        "      #mask_arr.size\r\n",
        "      predicted_class = tf.argmax(mask_arr, -1)\r\n",
        "      predicted_class = predicted_class[0, ...]\r\n",
        "      prediction_img = np.zeros([size_im[0], size_im[1]])\r\n",
        "      #prediction_img2 = np.zeros([size_im[0], size_im[1], 3])\r\n",
        "  \r\n",
        "      prediction_img[np.where(predicted_class == 0)] = 0\r\n",
        "      #prediction_img2[np.where(predicted_class == 0)] = [0, 0, 0]\r\n",
        "      for i in range(1, 3):\r\n",
        "        prediction_img[np.where(predicted_class == i)] = i\r\n",
        "        #prediction_img2[np.where(predicted_class == i)] = np.array(colors[i-1])[:3] * 255\r\n",
        "      #fig, ax = plt.subplots(1, 2, figsize=(10, 10))\r\n",
        "      #fig.show() \r\n",
        "      #print(np.uint8(prediction_img2).size)   \r\n",
        "      #ax[0].imshow(np.uint8(prediction_img2))\r\n",
        "      #ax[1].imshow(np.uint8(image[0]))\r\n",
        "      #fig.canvas.draw()\r\n",
        "      #time.sleep(1)\r\n",
        "\r\n",
        "      submission_dict[img_name]['shape'] = size_im\r\n",
        "      submission_dict[img_name]['team'] = test_set.projects[index]\r\n",
        "      submission_dict[img_name]['crop'] = test_set.plants[index]\r\n",
        "      submission_dict[img_name]['segmentation'] = {}\r\n",
        "    \r\n",
        "    # crop\r\n",
        "      rle_encoded_crop = rle_encode(prediction_img == 1)\r\n",
        "    # weed\r\n",
        "      rle_encoded_weed = rle_encode(prediction_img == 2)\r\n",
        "\r\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\r\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\r\n",
        "\r\n",
        "import json\r\n",
        "with open('/content/drive/My Drive/submission.json', 'w') as file:\r\n",
        "      json.dump(submission_dict, file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_y0KmLxZrf4_",
        "outputId": "14c59522-42c9-4743-84ef-44a28a1c9a81"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download(\"/content/drive/MyDrive/submission.json\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_59c7b077-1692-4593-8ea3-5daf74bd57e2\", \"submission.json\", 10175527)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}